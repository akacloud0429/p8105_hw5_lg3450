---
title: "p8105_hw5_lg3450"
output: github_document
---
first load all necessary libraries
```{r message=FALSE}
library(tidyverse)
library(broom)
library(scales)   
```

# Problem 1
**Suppose you put n people in a room, and want to know the probability that at least two people share a birthday. For simplicity, we’ll assume there are no leap years (i.e. there are only 365 days) and that birthdays are uniformly distributed over the year (which is actually not the case).**

* Q1.1: Write a function that, for a fixed group size, randomly draws “birthdays” for each person; checks whether there are duplicate birthdays in the group; and returns TRUE or FALSE based on the result.
```{r}
check_birthday = function(n) {
  #randomly draw #n birthdays from 1 to 365, allow for same bthd
  birthdays = sample(1:365, size = n, replace = TRUE)
  #logic: if length < n, duplication appears
  repeated_bthd = length(unique(birthdays)) < n
  repeated_bthd
}
```
* Q1.2: Next, run this function 10000 times for each group size between 2 and 50. For each group size, compute the probability that at least two people in the group will share a birthday by averaging across the 10000 simulation runs. 
```{r}
set.seed(1)

prob_results =
  expand_grid(
    group_size = 2:50,
    iter = 1:10000) |>
  mutate(
    repeated_bthd = map_dbl(group_size, check_birthday)) |>
  group_by(group_size) |>
  summarize(
    prob_shared = mean(repeated_bthd))

prob_results
```

* Q1.3: Make a plot showing the probability as a function of group size, and comment on your results.
```{r}
prob_results |>
  ggplot(aes(x = group_size, y = prob_shared)) +
  geom_point() +
  geom_path() +
  labs(
    title = "Estimated Probability of a Shared Birthday",
    x = "Group Size",
    y = "Probability of at least one shared birthday"
  ) +
  scale_y_continuous(labels = percent)
```

The plot illustrates a clear non-linear acceleration in probability, rather than a steady, linear increase. This simulation confirms the "birthday paradox," showing the 50% probability threshold is crossed with a group size of just 23. Following this point, the probability rapidly converges toward certainty, reaching 97% by a group size of 50.


# Problem2

**When designing an experiment or analysis, a common question is whether it is likely that a true effect will be detected – put differently, whether a false null hypothesis will be rejected. The probability that a false null hypothesis is rejected is referred to as power, and it depends on several factors, including: the sample size; the effect size; and the error variance. In this problem, you will conduct a simulation to explore power in a one-sample t-test.**

First set the following design elements: Fix n = 30, fix sigma = 5. Set $\mu\ = 0.Generate 5000 datasets from the model X∼Normal[$\mu\, sigma]. 

For each dataset, save $\mu\^ and the p-value arising from a test of H: $\mu\ = 0 using alpha = 0.05. Hint: to obtain the estimate aand p-value, using broom::tidat to clean the output of t.test.

Repeat the above for $\mu\ = {1,2,3,4,5,6}, and complete the following:

* Q2.1: Make a plot showing the proportion of times the null was rejected (the power of the test) on the y axis and the true value of $\mu\ on the x axis. Describe the association between effect size and power.

```{r}
set.seed(1)

run_ttest_sim = function(n_val, mu_val, sigma_val) {
  sim_data = rnorm(n = n_val, mean = mu_val, sd = sigma_val)
  tidy_result = broom::tidy(t.test(sim_data, mu = 0))
  tibble(
    mu_hat = tidy_result$estimate,
    p_value = tidy_result$p.value)
}

n_sims = 5000
n_val = 30
sigma_val = 5

power_results =
  expand_grid(
    true_mu = 0:6, 
    iter = 1:n_sims) |>
  mutate(
    results = map(true_mu, 
                  \(mu) run_ttest_sim(n_val = n_val, 
                                      mu_val = mu, 
                                      sigma_val = sigma_val))) |>
  unnest(results) |>
  group_by(true_mu) |>
  summarize(
    power = mean(p_value < 0.05))

power_plot =
  power_results |>
  ggplot(aes(x = true_mu, y = power)) +
  geom_point() +
  geom_path() + 
  labs(
    title = "Power of One-Sample t-test vs. Effect Size",
    x = "True Value of μ (Effect Size)",
    y = "Power (Proportion of Null Rejections)"
  ) +
  scale_y_continuous(labels = scales::percent) +
  scale_x_continuous(breaks = 0:6) 

power_plot
power_results
```

Based on the plot, the association between  and power is strong, positive, and non-linear. When the effect size is 0 (namely the null hypothesis is true), the power is low, at approximately 5%. As the effect size increases, the power (the probability of correctly detecting the effect) rises rapidly. The power is low for a small effect size, but approaches 100% for large effect sizes. In short, the larger the true effect, the more likely the test is to detect it.

* Q2.2: 






















